\begin{abstract}
	We propose an end-to-end deep learning framework that maps from a unit sphere surface to the target surface, given a single color image. 
	%Previous methods usually represent a 3D shape in volume or point cloud, and it is non-trivial to convert them to mesh models which are ready for wider application. 
	While mesh or surface models are widely used in many applications, it is challenging to apply the successful deep neural networks to directly produce surface models.  
	Unlike the methods that use volumetric or point representations, our method represents a 3D shape by a mapping from a fixed parameter domain. 
	%
	In our framework, the mapping is progressively carried out by the \emph{parameterization network}, given parameters that are predicted by the \emph{semantic network} from a single color image. 
	%
	By integrating mesh-based operation (e.g. Laplacian smooth) and mesh related losses into the network, our framework directly outputs high-quality meshes.
	Experiments show that our method not only produces mesh models that are more visually appealing, but also achieves comparable 3D shape estimation errors compared to the state of the art.
\end{abstract}