\section{Introduction}
The problem of point set generation from a single image is a problem of regressing shape with ambiguous input and output spaces. One of ambiguity arises from the fact that 3D-to-2D projection is not invertible and large portions of the shape features are excluded in the input image. We refer to this ambiguity in input space as \textit{semantic variation}. Another ambiguity arises from the fact that we can sample multiple point sets from the same shape and the discrepancy between these samples are not zero under common measurement(e.g. Chamfer Distance used in \citep{PSGN}). We refer to this ambiguity in output space as \textit{sampling variation}. These two kinds of ambiguity was not clearly identified and separated in \citep{PSGN}. Judged by the result shown in \citep{PSGN}, it seems that only some level of \textit{sampling variation} is successfully handled in the network proposed by \citep{PSGN}.

In order to handle these two kinds of ambiguity separately, we use a semantic network to predict parameters for a parameterization network that maps the unit sphere surface to the target surface. Such network structure can enable the separation of \textit{semantic variation} and \textit{sampling variation} in the way that the \textit{sampling variation} can be explored by sampling different point sets from the parameter domain (i.e. the unit sphere surface), leaving \textit{semantic variation} to be explored by adding random vector to 2D features.

In addition to the separation of \textit{semantic variation} and \textit{sampling variation}, we also propose such network structure to enable the representation of shape as spatial distribution. This perspective is inspired by VAE\citep{VAE} in the sense that a large portion of distribution can be approximated by standard normal distribution plus a learned complicate mapping. In our network, we actually represent the output shape using a uniform distribution defined on sphere surface plus a predicted complicate mapping (carried out by parameterization network). These two combined can represent complicate distribution of surface. Such representation also enable the network to generate mesh as output and enable the mesh related operation and losses for the network.

In summary, our contributions are
\begin{itemize}
	\item  Introduction of parameterization network that enable dense sampling and native mesh generation by representing the 3D shape as a spherical uniform distribution plus a learned/predicted mapping.
	\item  Exploring the idea that use semantic network to predict parameters for parameterization network. Such structure relate input image to parameterization network and enable the separation of \textit{semantic variation} and \textit{sampling variation}.
	\item Though bijective is not ensured for the predicted mapping now, with the ability to integrate mesh based operation and losses, our work is a steady step towards an actual \emph{parameterization prediction} that can enable other applications in computer graphics and computer vision.
\end{itemize}          

