\section{Experiments}
\begin{figure}[t]
	\centering
	\includegraphics[width=\linewidth]{img/opt/opt}
	\caption{Convergence of optimization. When optimized with our cycle regularization term, the term takes effect after only few iterations. It does not only keep the mapping injective during optimization but also corrects the self-intersection from the initialization. When optimized without cycle regularization term, the surface usually converges to a surface with self-intersection.}
	\label{fig:opt}
\end{figure}
\begin{wrapfigure}{r}{0.48\textwidth}
	\begin{center}
		\includegraphics[width=0.48\textwidth]{img/opt/lambda}
	\end{center}
	\caption{The choice of $\lambda$: Under the setting in Sec~\ref{subsec:deform}, we show some results with different choice of $\lambda$.}
	\label{fig:lambda}
\end{wrapfigure}
\begin{figure}[t]
	\centering
	\includegraphics[width=\linewidth]{img/atlas/svr}
	\caption{Cycle regularization on AtlasNet. All the visualized cases here are selected from the test set of AtlasNet. Some meshes' view direction are manually adjusted to better expose the differences. The red rectangles are highlighting a case (the table) in which more details are preserved than the original network because we are enforcing the injectivity with our cycle regularization term.}
	\label{fig:svr}
\end{figure}
\begin{figure}[t]
	\centering
	\includegraphics[width=\linewidth]{img/p2m/final}
	\caption{Cycle regularization on Pixel2Mesh: All the visualized cases here are selected from the test set of Pixel2Mesh. Some meshes' view direction are manually adjusted to better expose the differences. Our results shown here are from model trained with random $X$}
	\label{fig:p2m}
\end{figure}
\noindent{\textbf{Data}} To fairly evaluate the effect of cycle regularization, we use the datasets released by AtlasNet and Pixel2Mesh respectively. Their model sets are both subsets of ShapeNet \cite{shapenetdata} and they both used the rendered image from \cite{3DR2N2}. The absolute size and position of the models and the sampled points as ground truth are not processed in the same way in these two datasets, which makes it unreasonable to compare them all together. Therefore we evaluate the effect of our regularization technique with these two networks separately.

\noindent{\textbf{Training}}
Unless specifically explained, the network models shown in this paper are trained as follows: The parameters for image encoders and forward 3D decoders $\theta_f$ are initialized with parameters released by AtlasNet \cite{atlasnet} and Pixel2Mesh \cite{pixel2mesh} respectively. The parameters for inverse decoders $\theta_g$ are randomly initialized. We use the ADAM \cite{adam} optimizer with the same learning rate as in the original codes of AtlasNet and Pixel2Mesh respectively. We use $\lambda=0.25$ as an empirical choice for the weight of our cycle regularization term.

\noindent{\textbf{Evaluation Criteria}}
In order to quantitatively evaluate the issue of self-intersection and self-overlap, we count the percentage of self-intersected triangles (``SI") over the total number of triangles. For this evaluation, we provide our code in the supplemental material which calculates the ``SI" for an input mesh.  
We also use the value of Chamfer distance (``CD") as the original AtlasNet and Pixel2Mesh to evaluate how well the generated mesh approximate the target shape. For the evaluation of Chamfer distance we used the codes that are already implemented by AtlasNet \cite{atlasnet} and Pixel2Mesh \cite{pixel2mesh}.

\noindent{\textbf{Mesh Generation and Visualization}} Since we are addressing an issue regarding the quality of generated mesh, any post-processing used in AtlasNet \cite{atlasnet} is not used in our experiment. All the triangulations are directly transfered from the predefined surface. We do not divide the triangles to get denser vertices either. The meshes from AtlasNet all have 2500 vertices and about 4k faces. The meshes from Pixel2Mesh all have 2466 vertices and 4928 faces.

To better expose the issue we are addressing in this paper, we render the generated mesh in the software MeshLab and use the ``gooch.gdp" in the software as our shader. In such mode the triangles are rendered golden at front and bluish at back. The golden region and bluish region interlacing at surface evidently indicates the self-intersected surfaces.

\begin{table}
	\caption{Test error on AtlasNet trained with(\textbf{ours}) and without cycle regularization. Chamfer distance(CD) ($10^3$ times) and percentage of self-intersected(SI) faces are reported. ``AE" stands for the shape auto-encoding task, and ``SVR" stands for single view reconstruction task. Sphere means that the models are using sphere as predefined surface to sample points from. The mean is data-wise as it is implemented in the evaluation code of AtlasNet.}
	\label{tab:atlas}
	\centering
	\begin{tabular}{c|rc|rc|rc|rc|}
		\diagbox{Category}{CD,SI}{Model} &\multicolumn{4}{c|}{AE-sphere}&\multicolumn{4}{c|}{SVR-sphere}\\
		\cline{2-9}
		~& \multicolumn{2}{c|}{AtlasNet} & \multicolumn{2}{c|}{ours} & \multicolumn{2}{c|}{AtlasNet} & \multicolumn{2}{c|}{ours} \\
		\hline
		cellphone&1.3,&0.53\%&1.4,&3.4e-3\%&3.8,&1.4\%&3.7,&2.7e-4\%\\
		watercraft&1.5,&2.3\%&1.8,&6.8e-4\%&4.3,&7.4\%&4.3,&2.6e-4\%\\
		monitor&1.8,&1.8\%&2.0,&9.8e-4\%&6.9,&3.4\%&6.5,&9.8e-4\%\\
		car&1.8,&0.52\%&1.8,&8.0e-4\%&3.9,&0.47\%&3.8,&1.8e-3\%\\
		couch&1.9,&2.5\%&1.9,&8.8e-4\%&5.1,&2.0\%&4.9,&1.7e-3\%\\
		cabinet&2.0&2.3\%&2.2,&1.2e-2\%&5.3,&3.6\%&5.2,&4.3e-3\%\\
		lamp&2.7,&14\%&3.4,&5.5e-2\%&13.2,&19\%&13.1,&2.0e-2\%\\
		plane&1.0,&18\%&1.2,&1.9e-3\%&2.6,&18\%&2.6,&2.9e-3\%\\
		speaker&2.9,&0.77\%&2.9,&1.1e-3\%&10.2,&1.7\%&9.6,&3.1e-4\%\\
		bench&1.3,&11\%&1.6,&7.4e-3\%&4.0,&12.3\%&3.9,&1.6e-2\%\\
		table&1.7,&12\%&2.0,&2.1e-2\%&4.9,&10.7\%&4.8,&1.79e-5\%\\
		chair&1.9,&12\%&2.1,&2.7e-2\%&5.3,&10.9\%&5.3,&2.3e-2\%\\
		firearm&0.7,&4.9\%&0.9,&2.1e-3\%&2.2,&18.2\%&2.2,&1.2e-3\%\\
		\hline
		mean &1.7,&8.5\%&1.9,& 1.3e-2\% &5.2,&9.6\%&5.0,&1.2e-2\%\\
	\end{tabular}
\end{table}

\subsection{Visualize Deformation}
\label{subsec:deform}
\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{img/p2m/3level}
	\caption{Visualization of the effect of our cycle regularization in the coarse-to-fine framework of Pixel2Mesh. The green rectangle zoomed in on a subtle self-intersection. Our results shown here are from model trained with random $X$.}
	\label{fig:3level}
\end{figure}
In this subsection, we visualize the deformation process, providing a more intuitive view into the effect of our cycle regularization term. Being free of self-intersection is a rather geometric prior for surface mesh than a semantic one, therefore for the visualization in this section we do not involve any semantic networks and show the effect of our proposed technique in a pure shape deforming manner (different from the training neural networks). In other words, in this experiment, we optimize the same objective function as in Eq.~(\ref{equ:atlascycle}), but do not use semantic networks (neither ResNet-18 \cite{resnet} nor PointNet \cite{pointnet}) to generate the latent shape representation $\mathbf{s}$. We treat $\mathbf{s}$ as 1024 free variables.  We still use the same MLP for $f$ and $g$ as in Eq.~(\ref{equ:atlascycle}), but we are only trying to deform the output shape to approach a specific groundtruth shape in this experiment. We initialize the parameters $\theta_f,\theta_g,\mathbf{s}$ randomly with standard normal distribution and sample $X$ from sphere surface in this experiment. For optimizer, we use gradient descent. Under such setting, we are deforming a randomly initialized shape (probably start with self-intersection) to approach a specific groundtruth shape. As in Figure~\ref{fig:opt}, the case of two groundtruth shapes (downloaded from the Internet) are shown. In these two cases, after few iterations our cycle regularization term takes effect. It not only keep the mapping injective in following iterations but also corrects the self-intersection from the initialization.

\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{img/limit/limit}
	\caption{Failure cases of our cycle regularization. Though the self-intersection are significantly reduced for most cases, it is not entirely removed in the results.}
	\label{fig:limit}
\end{figure}

As shown in Figure~\ref{fig:lambda}, visually speaking, when we set the weight $\lambda=0.25$, the deformed shape is able to approximate more details than the larger choices (i.e. $\lambda=0.5,1.0$), and it is also sufficient to enforce the injective mapping.  Therefore we use $\lambda=0.25$ as an empirical choice in following experiments, however finer tuning for specific networks is possible.

This experiment proves that our cycle regularization works with standard gradient decent optimization. In experiments of following subsections,  we will see how it extends to stochastic gradient decent optimization.

\subsection{AtlasNet with Cycle Regularization}
In this subsection, we show and discuss the effect of our cycle regularization term on AtlasNet \cite{atlasnet}. As shown in Table~\ref{tab:atlas}, after applying our cycle regularization on the AtlasNet(sphere), the percentage of self-intersected triangles (``SI") are significantly reduced, while the Chamfer distance (``CD") remains close to original networks (somehow slightly worse in auto-encoding and better in single view reconstruction task). As visualized in Figure~\ref{fig:svr} for single view reconstruction task, the reduction of self-intersection is also visually evident. In some cases, as the one highlighted by red rectangles in Figure~\ref{fig:svr}, our cycle regularization term even helps to improve the reconstructed details.

\subsection{Pixel2Mesh with Cycle Regularization}
In this subsection, we show and discuss the effect of our cycle regularization term on Pixel2Mesh \cite{pixel2mesh}. As visualized in Figure~\ref{fig:p2m}, the reduction of self-intersection is visually evident. As the examples shown in Figure~\ref{fig:3level}, our cycle regularization takes effect in all three levels in the coarse-to-fine framework of Pixel2Mesh. In Table~\ref{tab:p2m}, when applying our cycle regularization on the Pixel2Mesh, the percentage of self-intersected triangles (``SI") are significantly reduced, while the Chamfer distance (``CD") remains close to original Pixel2Mesh. We can also see that our cycle regularization works better when trained with random $X$, especially by the measure of self-intersection. The model trained with random $X$ (sampled as in Eq.\ref{equ:sample}) has lower average percentage of self-intersected triangles across almost all categories (except cellphone and cabinet).
\begin{table}
	\caption{Test error on Pixel2Mesh trained with(\textbf{ours}) and without cycle regularization. For cycle regularization, the cases with fixed $X$ (the vertices of the ellipsoids as $X$) and random $X$ (sampled as in Eq.\ref{equ:sample}) are both evaluated. Chamfer distance(CD) and percentage of self-intersected(SI) faces are reported. The mean is data-wise calculated.}
	\label{tab:p2m}
	\centering
	\begin{tabular}{c|rc|rc|rc|}
		\diagbox{Category}{CD,SI}{Model}&\multicolumn{2}{c|}{\multirow{2}{*}{Pixel2Mesh}}&\multicolumn{4}{c|}{ours}\\
		\cline{2-7}
		~&~&~&\multicolumn{2}{c|}{Fixed $X$}&\multicolumn{2}{c|}{Random $X$}\\
		\hline
		cellphone&0.303,&0.22\%&0.304,&3.85e-3\%&0.288,&3.85e-3\%\\
		watercraft&0.433,&0.84\%&0.438,&2.51e-2\%&0.433,&1.25e-2\%\\
		monitor&0.390,&0.585\%&0.425,&1.15e-2\%&0.397,&9.27e-3\%\\
		car&0.233,&0.145\%&0.242,&1.39e-3\%&0.239,&1.24e-3\%\\
		couch&0.361,&0.21\%&0.384,&3.67e-3\%&0.377,&2.26e-3\%\\
		cabinet&0.268,&0.167\%&0.283,&5.32e-3\%&0.276,&5.80e-3\%\\
		lamp&0.728,&10.3\%&0.788,&0.190\%&0.795,&0.182\%\\
		plane&0.265,&1.82\%&0.300,&3.75e-2\%&0.289,&3.37e-2\%\\
		speaker&0.523,&0.487\%&0.524,&5.39e-3\%&0.523,&5.34e-3\%\\
		bench&0.323,&1.13\%&0.349,&3.32e-2\%&0.350,&1.48e-2\%\\
		table&0.304,&1.17\%&0.333,&4.98e-2\%&0.330,&3.87e-2\%\\
		chair&0.392,&1.68\%&0.420,&6.82e-2\%&0.414,&5.10e-2\%\\
		firearm&0.326,&1.86\%&0.352,&8.64e-2\%&0.349,&7.36e-2\%\\
		\hline
		mean &0.345,&1.47\%&0.369,& 4.20e-2\%&0.364,& 3.45e-2\%\\
	\end{tabular}
\end{table}

\subsection{Limitations and Future Work}
Averagely speaking, with our cycle regularization, less than one self-intersected triangles are generated in each output mesh. However, the self-intersection are not totally prevented after all. As in Figure~\ref{fig:limit}, some failure cases are shown. In the future,  we would like to deduce a more elegent hard constraint on the network parameters and make multilayer perception injective. 

Our cycle regularization is only validly deduced for the cases that the mesh reconstruction network map from only one predefined surface to target surface. This fundamental limitation prevents us to apply it for surfaces with more complicated topology. However, we believe a possible better solution for this limitation would be applying mask on the surface to handle the holes instead of using multiple parameter domain. We maybe able to using attention techniques in deep learning to predict such masks.