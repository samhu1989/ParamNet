<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3c.org/TR/1999/REC-html401-19991224/loose.dtd">
<!-- saved from url=(0061)http://staff.ustc.edu.cn/~xjchen99/FoldingCartons.html -->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><HTML 
xmlns="http://www.w3.org/1999/xhtml"><HEAD><META content="IE=11.0000" 
http-equiv="X-UA-Compatible">
 
<META http-equiv="Content-Type" content="text/html; charset=utf-8"> 
<TITLE>ParamNet</TITLE> 
<STYLE type="text/css">
.ys01 {
	font-size: 30px;
	font-family: Arial, Helvetica, sans-serif;
	font-weight: bold;
	color: #57524C;
}
.ys02 {
	font-family: Arial, Helvetica, sans-serif;
	font-weight: bold;
	color: #6293A2;
	text-align: center;
}
.ys2 {
}
.ys2 {
	font-weight: bold;
	font-family: Arial, Helvetica, sans-serif;
	font-size: 16px;
	color: #6293A2;
	text-align: center;
}
.ys2 sup {
	color: #57524C;
}
.ys3 {
	font-weight: bold;
}
.ys3 {
	font-family: Arial, Helvetica, sans-serif;
}
.ys3 {
	text-align: center;
	color: #57524C;
}
.ys3 {
}
.ys4 {
	text-align: center;
}
.ys2 .ys2 {
	color: #57524C;
}
.ys5 {
	font-weight: bold;
	font-family: Arial, Helvetica, sans-serif;
}
.ys6 {
	font-family: Arial, Helvetica, sans-serif;
}
.ys7 {
	text-align: center;
}
a:link {
	text-decoration: none;
}
a:visited {
	text-decoration: none;
}
a:hover {
	text-decoration: underline;
}
a:active {
	text-decoration: none;
}
.teaser {
	font-weight: bold;
	font-family: "Times New Roman", Times, serif;
	color: #57524C;
	text-align: left;
}
.text {
	font-family: "Times New Roman", Times, serif;
	color: #57524C;
	text-align: justify;
	font-weight: normal;
}
.title1 {
	font-family: Arial, Helvetica, sans-serif;
	color: #6293A2;
	font-weight: bold;
	text-align: left;
	font-size: 18px;
}
.text2 {
	text-align: justify;
	font-family: "Times New Roman", Times, serif;
	color: #57524C;
	font-weight: normal;
}
.title1 .teaser {
	text-align: justify;
}
.copyright {
	font-family: "Times New Roman", Times, serif;
	color: #57524C;
	text-align: right;
}
.copy {
	font-family: "Times New Roman", Times, serif;
	text-align: right;
	color: #57524C;
}
.download {
}
.download {
	font-family: Arial, Helvetica, sans-serif;
}
.download {
	font-weight: bold;
}
.download {
	color: #6293A2;
}
body {
	background-color: #FFFFFF;
	text-align: center;
}
.teaser {
	text-align: justify;
}
.copy1 {
	text-align: right;
	color: #000;
	font-family: Arial, Helvetica, sans-serif;
	font-size: 14px;
}
.STYLE17 {font-size: medium}
.style1 {	FONT-FAMILY: "Times New Roman", Times, Verdana, Arial, Helvetica, sans-serif ;
	FONT-SIZE: 18px
}
</STYLE>
 
<meta name="generator" content="Bluefish 2.2.10" ></HEAD> 
<BODY>
<TABLE width="1044" align="center" background="">
  <TBODY>
  <TR>
    <TD width="1044" height="3355" align="center" valign="top">
      <P>&nbsp;</P>
      <TABLE width="900">
        <TBODY>
        <TR>
          <TD>
            <P align="center" class="ys01">Preventing Self-Intersection with Cycle Regularization in Neural Networks for Mesh Reconstruction from a Single RGB Image</P>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            &nbsp;&nbsp;&nbsp;&nbsp;
            <A href="https://samhu1989.github.io/" target="_new">Siyu Hu</A>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <A href="http://staff.ustc.edu.cn/~xjchen99" target="_new">Xuejin Chen*</A>        
              
            <P class="ys2"><A href="http://www.ustc.edu.cn/" 
            target="_new">University of Science and Technology of China</A></P>
            <P class="ys2">Computer Aided Geometric Design 2019</P></TD></TR>
        <TR>
          <TD>
            <P class="ys02"><IMG width="800" alt="network" src="./net.png"></P>
            <TABLE width="800" height="21" align="center" 
        border="0"></TABLE></TD></TR>
        <TR>
          <TD>
            <P class="teaser">Figure 1:<SPAN class="text"> The cycle regularization implemented along with two networks. (a) is the implementation with AtlasNet Groueix et al. (2018). f is the forward 3D surface decoder in the original network and g is our inverse decoder used to form the regularization term. (b) is the implementation with Pixel2Mesh Wang et al. (2018). Pixel2Mesh Wang et al. (2018) adopts the coarse-to-fine framework and uses three G-ResNet blocks (f1 , f2 , f3) to map the mesh to target shape on three different point density. The graph-unpooling layers are used for mesh upsampling. We use three point-wise MLP (g1 , g2 , g3) as the inverse decoders for each level of point density and form a regularization term for each level.</SPAN></P></TD></TR>
        <TR>
          <TD>&nbsp;</TD></TR>
        <TR>
          <TD>
            <P class="title1">Abstract:</P></TD></TR>
        <TR>
          <TD>
            <P class="text2"> Self-intersection in surfaces is a typical defect that makes a 3D model unsuitable for many applications. Existing neural networks for 3D surface mesh reconstruction are faced with the challenge of integrating self-intersection prevention. In this paper, we propose a trainable cycle regularization in mesh reconstruction networks to prevent self-intersection. It is a general technique that can be easily implemented with existing surface mesh generation networks. Our experiments on two latest mesh reconstruction networks demonstrate that with the proposed cycle regularization, self-intersections in the generated meshes are significantly reduced, while the shape similarity is comparable with the original networks under the Chamfer distance metric.  </P></TD></TR>
        <TR>
          <TD>&nbsp;</TD></TR>
        <TR>
          <TD>
            <P class="title1">Results:</P></TD></TR>
        <TR>
          <TD>
            <DIV align="center"><IMG width="800" alt="atlas_svr" src="./atlas_svr.png"></DIV></TD></TR>
        <TR>
          <TD>
            <DIV align="left"><SPAN class="teaser">Figure 2:</SPAN> <SPAN 
            class="text"> Cycle regularization on AtlasNet. All the visualized cases here are selected from the test set of AtlasNet. We manually adjust the view direction for some meshes to better expose the differences. The red rectangles highlight a case where more details are preserved than the original network because injectivity is enforced with our cycle regularization.</SPAN></DIV></TD></TR>
        <TR>
          <TD>&nbsp;</TD></TR>
        <TR>
          <TD>
            <DIV align="center"><IMG width="800" alt="p2m_svr" src="./p2m_svr.png"></DIV></TD></TR>
        <TR>
          <TD>
            <DIV align="left"><SPAN class="teaser">Figure 3:</SPAN><SPAN 
            class="text"> <SPAN class="text2">Cycle regularization on Pixel2Mesh. These examples are selected from the test set of Pixel2Mesh. We adjust the view direction for some meshes to better expose the differences.
            </SPAN></SPAN></DIV></TD></TR>
        <TR>
          <TD>&nbsp;</TD></TR>
        <TR>
          <TD>
            <DIV align="center"><IMG width="800" alt="p2m_3level" src="./3level.png"></DIV></TD></TR>
        <TR>
          <TD>
            <DIV align="left"><SPAN class="teaser">Figure 4:</SPAN><SPAN 
            class="text"> <SPAN class="text2">Visualization of the effect of our cycle regularization in the coarse-to-fine framework of Pixel2Mesh. The green rectangle shows a close-up view of a subtle self-intersection in the airplane model.
            </SPAN></SPAN></DIV></TD></TR>
        <TR>
          <TD>&nbsp;</TD></TR>
        <TR>
       

        <TR>
          <TD><SPAN class="title1">Acknowledgements:</SPAN></TD></TR>
        <TR>
          <TD>
            <P class="text2"> We would like to thank Dr. Xin Tong and Hao Su for their insightful comments and suggestions. This work was supported by the National Key Research and Development Plan of China under Grant No. 2016YFB1001402, the National Natural Science Foundation under Grant No. 61632006, and the Fundamental Research Funds for the Central Universities under Grant WK3490000003.
            </P></TD></TR>
        <TR>
          <TD>&nbsp;</TD></TR>
        <TR>
          <TD><SPAN class="title1">Main References:</SPAN></TD></TR>
        <TR>
          <TD>
            <P class="text2"> [1] Wang, N., Zhang, Y., Li, Z., Fu, Y., Liu, W., Jiang, Y.G., 2018. Pixel2mesh: generating 3D mesh models from single RGB images. In: The European Conference on Computer Vision. ECCV.
            <P class="text2"> [2] Groueix, T., Fisher, M., Kim, V.G., Russell, B.C., Aubry, M., 2018. A papier-mâché approach to learning 3D surface generation. In: The IEEE Conference on Computer Vision and Pattern Recognition. CVPR.
        </P></TD></TR>
        <TR>
        <TR>
          <TD>&nbsp;</TD></TR>
        <TR>
          <TD><SPAN class="title1">BibTex:</SPAN></TD></TR>
        <TR>
          <TD><SPAN class="text2">@article{HU201984,<BR>
               title = "Preventing self-intersection with cycle regularization in neural networks for mesh reconstruction from a single RGB image",<BR>
               journal = "Computer Aided Geometric Design",<BR>
               volume = "72",<BR>
               pages = "84 - 97",<BR>
               year = "2019",<BR>
               issn = "0167-8396",<BR>
               doi = "https://doi.org/10.1016/j.cagd.2019.06.001",<BR>
               url = "http://www.sciencedirect.com/science/article/pii/S0167839619300548",<BR>
               author = "Siyu Hu and Xuejin Chen"<BR>}</SPAN></TD></TR>
        <TR>
          <TD>&nbsp;</TD></TR>
        <TR>
          <TD><SPAN class="title1">Downloads:</SPAN></TD></TR>
        <TR>
          <TD><SPAN class="text2">Disclaimer: The paper listed on this page is 
            copyright-protected. By clicking on the paper link below, you 
            confirm that you or your institution have the right to access the 
            corresponding pdf file.</SPAN></TD></TR>
        <TR>
          <TD>
            <UL>
              <LI class="download"><A href="./ParamNet.pdf">Paper 
              </A></LI>
              <LI class="download"><A href="https://data.mendeley.com/datasets/52z7nxkkz6/draft?a=3e7e6179-8290-4dea-9025-1998a594da12">Code and Trained Model</A></LI></UL></TD></TR></TBODY></TABLE>
      <TABLE width="900" align="center">
        <TBODY>
        <TR>
          <TD>
            <HR>
          </TD></TR>
        <TR>
          <TD class="copy1">Copyright © 2018 GCL&nbsp;, 
      USTC</TD></TR></TBODY></TABLE>
      <P>&nbsp;</P></TD></TR></TBODY></TABLE></BODY></HTML>
